# Data Scientist

![EEG Band Discovery](/assets/img/Hello.png)

Heyyy !! Si tu es là, c’est que tu veux en savoir plus sur moi (*ou alors tu t’es perdu, dans ce cas bienvenue quand même 😆*). Allez, installe-toi confortablement, prends un café ☕ et découvre mon parcours !

___


## 🧐 Qui suis-je vraiment ?

Je m'appelle Abdoul Kader, et je m’intéresse à tout ce qui touche à la donnée, surtout quand elle peut être mise au service de décisions concrètes. J’ai commencé par une licence en Économie, où j’ai appris à manier les chiffres et les stats, avant de m’orienter vers un master en Systèmes d’Information et Aide à la Décision à l’Université de Lille. C’est là que j’ai découvert l’univers de la data, et j’y ai vite pris goût.

Depuis mai 2024, je suis en alternance chez **Okaïdi**, dans l’équipe Performance Client. Mon rôle ? Travailler sur des sujets data liés au CRM et au marketing. J’ai notamment construit un **score d’appétence SMS** 📲 pour améliorer le ciblage des campagnes, et réalisé plusieurs analyses autour de la **segmentation client**. Ce que j’aime dans ces projets, c’est qu’ils mêlent technique, logique métier et impact réel.

Je travaille surtout avec **SQL, Python, Looker et BigQuery**, dans un environnement cloud (GCP). J’apprécie autant creuser les données que comprendre les besoins des équipes métier pour y répondre au mieux.

🔍 **Et la suite ?** Je suis à la recherche d’une nouvelle opportunité dans la data à partir de **septembre 2025**. J’aimerais continuer à apprendre, contribuer à des projets utiles, et évoluer dans une équipe où la collaboration compte.

📩 **Pour échanger :**  
- [https://www.linkedin.com/in/kader-761148222/](#) 💼  
- 📧 **Email** : kadermk1088@gmail.com

---

## 🛠️ Compétences Techniques  

### Langages  
![SQL](https://img.shields.io/badge/SQL-025E8C?style=for-the-badge&logo=postgresql&logoColor=white)  ![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)  ![R](https://img.shields.io/badge/R-276DC3?style=for-the-badge&logo=r&logoColor=white)  ![SAS](https://img.shields.io/badge/SAS-003366?style=for-the-badge&logo=sas&logoColor=white)  ![VBA](https://img.shields.io/badge/VBA-217346?style=for-the-badge&logo=microsoft-excel&logoColor=white)  

### Outils & Cloud  
![BigQuery](https://img.shields.io/badge/BigQuery-4285F4?style=for-the-badge&logo=google-cloud&logoColor=white)  ![Looker](https://img.shields.io/badge/Looker-4285F4?style=for-the-badge&logo=looker&logoColor=white)  

### Visualisation  
![Looker](https://img.shields.io/badge/Looker-4285F4?style=for-the-badge&logo=looker&logoColor=white)  ![Matplotlib](https://img.shields.io/badge/Matplotlib-11557C?style=for-the-badge&logo=python&logoColor=white)  ![Seaborn](https://img.shields.io/badge/Seaborn-009688?style=for-the-badge&logo=python&logoColor=white)  ![ggplot](https://img.shields.io/badge/ggplot-D14F4F?style=for-the-badge&logo=r&logoColor=white)  ![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=streamlit&logoColor=white)  

### Machine Learning & Stats  
![Scikit-learn](https://img.shields.io/badge/Scikit--learn-F7931E?style=for-the-badge&logo=scikitlearn&logoColor=white)  ![TensorFlow](https://img.shields.io/badge/TensorFlow-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white)  

### Business Intelligence  
![Power BI](https://img.shields.io/badge/Power%20BI-F2C811?style=for-the-badge&logo=powerbi&logoColor=black)  ![Tableau](https://img.shields.io/badge/Tableau-E97627?style=for-the-badge&logo=tableau&logoColor=white)  ![Semarchy](https://img.shields.io/badge/Semarchy-0073CF?style=for-the-badge&logo=data&logoColor=white)  ![Business Object](https://img.shields.io/badge/Business%20Object-003366?style=for-the-badge&logo=sap&logoColor=white)  

### Autres  
![Git](https://img.shields.io/badge/Git-F05032?style=for-the-badge&logo=git&logoColor=white)  ![API](https://img.shields.io/badge/API-0088CC?style=for-the-badge&logo=fastapi&logoColor=white)  

---

## 💡 Soft Skills 

- **Esprit analytique** – Capacité à extraire des insights pertinents et à proposer des recommandations data-driven.  
- **Travail en équipe** – Expérience en collaboration avec des équipes métiers, IT et marketing.  
- **Résolution de problèmes** – Approche méthodique pour résoudre des problématiques complexes.  
- **Communication** – Capacité à vulgariser des concepts techniques pour les rendre accessibles aux non-experts.  
- **Adaptabilité** – Capacité à apprendre rapidement de nouvelles technologies et méthodologies.  
- **Curieux** – Toujours à l’affût des nouvelles tendances et technologies en data science.

---

## 🎓 Formation

### 📌 Master 2 Systèmes d'Information et Aide à la Décision (SIAD)  
**Université de Lille** | 09/2023 - 09/2025

**🎯 Objectif de la formation**  
Former des spécialistes capables de maîtriser l'ensemble de la chaîne de traitement de l'information, combinant compétences en informatique décisionnelle, statistiques avancées et compréhension des logiques métiers, pour accompagner la prise de décision dans des environnements riches en données.

**📚 Compétences & matières clés**  
- 🔹 **Informatique décisionnelle** : modélisation de données, bases de données relationnelles, ETL/ELT, requêteurs, logiciels d'interrogation.  
- 🔹 **Méthodes statistiques avancées**: analyse de données, régressions économétriques, data mining, traitement des données massives.  
- 🔹 **Économie et gestion** : compréhension des mécanismes économiques fondamentaux, fonctions de l'entreprise (marketing, comptabilité, contrôle).  
- 🔹 **Professionnalisation** : stages, projets tutorés, préparation à l'insertion professionnelle.  
- 🔹 **Big Data & Machine Learning** : apprentissage automatique et traitement de grandes volumétries de données.  
- 🔹 **Traitement du langage naturel (NLP)** : analyse et modélisation du langage pour extraire des informations pertinentes.  

**🛠️ Technologies abordées** : Python, R, SQL, Power BI, outils ETL, plateformes Big Data.  

---

### 📌 Licence en Économie  
**Université de Bourgogne** | 09/2020 - 08/2023

**🎯 Objectif de la formation**  
Acquérir une solide culture économique générale, associée à des compétences quantitatives et analytiques, pour comprendre et interpréter les phénomènes économiques contemporains.

**📚 Compétences & matières clés**  
- 🔹 **Microéconomie & Macroéconomie** : théorie du consommateur et du producteur, modèles d'équilibre général, politiques économiques.  
- 🔹 **Statistiques et économétrie** : statistiques descriptives univariées et bivariées, probabilités, inférence statistique, introduction à l'économétrie.  
- 🔹 **Mathématiques appliquées** : mathématiques financières, optimisation, calcul différentiel et intégral.  
- 🔹 **Histoire économique** : faits économiques et sociaux, histoire de la pensée économique.  
- 🔹 **Langues étrangères** : anglais des affaires, options en espagnol ou allemand.  
- 🔹 **Projets thématiques** : travaux dirigés, restitutions écrites et orales, analyse de données économiques.  

**🛠️ Technologies abordées** : Excel, logiciels statistiques, outils de bureautique.  

---

## 💼 Expériences Professionnelles  

### 📌 Data Scientist (Stage + Alternance) | Okaïdi | Mai 2024 – Aujourd’hui  
Participation à des projets au service de la performance client, en lien étroit avec les équipes CRM et Data.

---

#### 🔹 Analyse de la segmentation client  
🚀 **Problème à résoudre**  
Mieux exploiter une segmentation récemment mise en place pour améliorer la connaissance client et affiner les ciblages marketing.  

📌 **Réalisations**  
- Analyse des comportements d’achat et des canaux d’interaction (site, magasins, email, SMS).  
- Études croisées entre les segments et les KPIs commerciaux (CA, fréquence, rétention).  

🛠️ **Technologies** : SQL, Python, Looker, BigQuery  

🎯 **Résultats**  
- Segmentation enrichie de profils comportementaux.  
- Meilleur ciblage des campagnes, cohérent avec les typologies clients.

---

#### 🔹 Migration de cas d’usage data  
🚀 **Problème à résoudre**  
Assurer la continuité des analyses et automatisations lors de la migration d’une ancienne plateforme vers Google Cloud Platform.  

📌 **Réalisations**  
- Analyse des cas d’usage existants et mapping vers les nouvelles sources.  
- Refonte des requêtes et reconstruction des pipelines dans BigQuery.  
- Mise en place de jeux de tests et de recettes pour validation.  

🛠️ **Technologies** : SQL, BigQuery, GCP  

🎯 **Résultats**  
- Reprise complète des cas d’usage critiques sans perte de données.  
- Données plus accessibles et traitements plus rapides sur la nouvelle plateforme.

---

#### 🔹 Construction d’un score d’appétence SMS  
🚀 **Problème à résoudre**  
Identifier les clients les plus sensibles aux campagnes SMS pour optimiser les performances CRM et éviter le gaspillage budgétaire.  

📌 **Réalisations**  
- Modélisation basée sur l’uplift : comparaison clients ciblés vs témoins.  
- Sélection de features explicatives : récence, fréquence, canaux utilisés, segments, etc.  
- Tests de performance et intégration dans les outils CRM.  

🛠️ **Technologies** : Python, SQL, BigQuery ML  

🎯 **Résultats**  
- Score d’appétence intégré dans les campagnes.  
- Taux de conversion SMS amélioré et budget marketing mieux ciblé.

---

## 🚀 Projets Perso et académiques *(Parce que j’aime expérimenter en dehors du boulot)*

### 🏥 Conception d'une Base de Données pour un Cabinet Dentaire

#### ❓ Problème à résoudre  
Fournir à un cabinet dentaire une solution structurée pour centraliser les données patients (comptes, adresses, contacts) afin d’améliorer le suivi administratif et la gestion quotidienne.

#### 🛠️ Technologies  
![SQL](https://img.shields.io/badge/SQL-025E8C?style=for-the-badge&logo=postgresql&logoColor=white)  
![Semarchy](https://img.shields.io/badge/Semarchy-0073CF?style=for-the-badge&logo=data&logoColor=white)  
![Power BI](https://img.shields.io/badge/Power%20BI-F2C811?style=for-the-badge&logo=powerbi&logoColor=black)

#### 📌 Réalisations  
✅ Modélisation conceptuelle et logique des données (MCD & MLD) pour structurer l’information autour des patients.  
✅ Intégration des données issues de fichiers plats via un processus ETL automatisé (nettoyage, transformation, contrôle qualité) sous Semarchy xDI.  
✅ Création d’un tableau de bord Power BI connecté, offrant une visualisation claire des données patients et un moteur de recherche performant.

#### 🎯 Résultats  
🔹 Base de données centralisée et fiable facilitant la gestion des patients.  
🔹 ETL robuste réduisant les erreurs humaines et assurant la qualité des données.  
🔹 Dashboard intuitif pour un pilotage efficace de l’activité du cabinet.

📂 **Lien vers le projet** : [Accéder au projet](https://github.com/Derka88/cabinet-datawarehouse)

<br> 

### 🚗 Étude des Impacts des Mesures de Sécurité Routière sur les Autoroutes Françaises

#### ❓ Problème à résoudre  
Évaluer l’efficacité des différentes mesures de sécurité routière mises en place sur les autoroutes françaises, en analysant leur impact sur le nombre d’accidents et de décès.

#### 🛠️ Technologies  
![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)

#### 📌 Réalisations  
✅ **Exploration des données** – Analyse d’une base d’accidents sur les autoroutes françaises.  
✅ **Intégration de données externes** – Recherche et collecte des mesures de sécurité mises en place au fil du temps.  
✅ **Visualisation & analyse exploratoire** – Étude des tendances d’accidents et de mortalité avant/après les mesures.  
✅ **Modélisation statistique** – Quantification de l’impact des mesures via des modèles statistiques et visuels interactifs.  
✅ **Recommandations stratégiques** – Propositions d’amélioration basées sur les données analysées.

#### 🎯 Résultats  
🔹 **Identification des mesures les plus efficaces** pour réduire les accidents et décès.  
🔹 **Mise en lumière de périodes critiques** et des tendances structurelles.  
🔹 **Recommandations data-driven** pour guider les futures politiques de sécurité.

📂 **Lien vers le projet** : [Accéder au projet](https://github.com/Derka88/cabinet-datawarehouse)

<br>

### 🏦 Segmentation Client par Clustering pour une Banque en Ligne

#### ❓ Problème à résoudre  
Améliorer la connaissance client et renforcer l’efficacité des actions marketing grâce à une segmentation basée sur le clustering, afin de mieux personnaliser l’expérience utilisateur.

#### 🛠️ Technologies  
![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)  
![R](https://img.shields.io/badge/R-276DC3?style=for-the-badge&logo=r&logoColor=white)

#### 📌 Réalisations  
✅ **Exploration des données** – Analyse descriptive des caractéristiques clients pour identifier les variables pertinentes.  
✅ **Prétraitement** – Sélection et transformation des variables pour améliorer la qualité des segments.  
✅ **Analyse des Correspondances Multiples (ACM)** – Réduction de la dimensionnalité pour visualiser les liens entre variables.  
✅ **Segmentation** – Application de la Classification Ascendante Hiérarchique (CAH) et du K-means pour former des groupes homogènes.  
✅ **Modèle d’affectation** – Développement d’un algorithme pour assigner les nouveaux clients aux segments identifiés.

#### 🎯 Résultats  
🔹 **Profils clients distincts** identifiés pour une personnalisation des services.  
🔹 **Campagnes marketing optimisées** grâce à une segmentation pertinente.  
🔹 **Expérience utilisateur enrichie** via l’adaptation des offres et interfaces.

📂 **Lien vers le projet** : [Accéder au projet](https://github.com/Derka88/cabinet-datawarehouse)


<br>

### 🌪️ Détection de Tweets Catastrophes par Analyse de Langage Naturel

#### ❓ Problème à résoudre  
Développer un système capable de distinguer automatiquement les tweets rapportant de réelles catastrophes de ceux utilisant un langage similaire de manière non littérale, afin d'améliorer la veille informationnelle lors d'événements critiques. *(Basé sur une compétition Kaggle).*

#### 🛠️ Technologies  
![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)  
![Scikit-learn](https://img.shields.io/badge/Scikit--Learn-F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white)  
![Pandas](https://img.shields.io/badge/Pandas-150458?style=for-the-badge&logo=pandas&logoColor=white)  
![NLTK](https://img.shields.io/badge/NLTK-8A2BE2?style=for-the-badge)  
![Keras](https://img.shields.io/badge/Keras-D00000?style=for-the-badge&logo=keras&logoColor=white)  
![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=streamlit&logoColor=white)

#### 📌 Réalisations  
✅ **Prétraitement des données textuelles** – Nettoyage, tokenisation, lemmatisation pour standardiser les textes.  
✅ **Extraction de features** – Utilisation de Bag of Words, TF-IDF et embeddings BERT pour capter les nuances sémantiques.  
✅ **Modélisation** – Entraînement de plusieurs modèles : Régression Logistique, Random Forest, XGBoost, et fine-tuning de modèles BERT.  
✅ **Déploiement** – Création d'une application Streamlit permettant de tester le modèle en temps réel sur de nouveaux tweets.

#### 🎯 Résultats  
🔹 **Modèle performant** pour l’identification automatique des tweets signalant de vraies catastrophes.  
🔹 **Application web interactive** facilitant l’évaluation et la démonstration du modèle.  
🔹 **Montée en compétences en NLP avancé** grâce à l'intégration de BERT et d'outils de déploiement simples.

📂 **Lien vers le projet** : [Accéder au projet](https://github.com/Derka88/cabinet-datawarehouse)

<br>

### ⚡ MLOps – Prévision de la Consommation Électrique Nationale

#### ❓ Problème à résoudre  
Mettre en place un pipeline MLOps robuste pour prévoir la consommation électrique nationale (basée sur les données RTE), en assurant la reproductibilité des expériences et le suivi des performances des modèles.

#### 🛠️ Technologies  
![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)  
![MLflow](https://img.shields.io/badge/MLflow-0194E2?style=for-the-badge&logo=mlflow&logoColor=white)

#### 📌 Réalisations  
✅ **Analyse exploratoire** des données RTE : identification des tendances, saisonnalités et anomalies.  
✅ **Visualisation des séries temporelles** pour comprendre les patterns de consommation.  
✅ **Feature engineering temporel** – Variables calendaires, encodage cyclique (jour, semaine, mois, année), lags.  
✅ **Modélisation** – Entraînement de modèles statistiques et de machine learning (ex : Gradient Boosting).  
✅ **Suivi des expérimentations avec MLflow** – Tracking des hyperparamètres, métriques et artefacts pour une meilleure reproductibilité.

#### 🎯 Résultats  
🔹 **Modèles prédictifs efficaces** pour la prévision de la consommation à court et moyen terme.  
🔹 **Pipeline MLOps structuré** assurant traçabilité et comparabilité des versions de modèles.  
🔹 **Insights métier** sur les facteurs influençant la consommation électrique nationale.

📂 **Lien vers le projet** : [Accéder au projet](https://github.com/Derka88/cabinet-datawarehouse)

<br>

### 🌍 Datawarehouse Ventes Internationales – Okaïdi

#### ❓ Problème à résoudre  
Fournir une vision consolidée et fiable des indicateurs de vente à l'international pour l'entreprise Okaïdi, en centralisant des données provenant de différentes sources (fichiers de caisse, référentiels articles).  
*(Clarification : ce projet est distinct de mon expérience professionnelle chez Okaïdi).*

#### 🛠️ Technologies  
![SQL](https://img.shields.io/badge/SQL-4479A1?style=for-the-badge&logo=postgresql&logoColor=white)  
![Semarchy](https://img.shields.io/badge/Semarchy-xDI-blue?style=for-the-badge)  
![Power BI](https://img.shields.io/badge/Power%20BI-F2C811?style=for-the-badge&logo=powerbi&logoColor=black)

#### 📌 Réalisations  
✅ **Modélisation d’un datawarehouse en étoile** – Conception des tables de faits et dimensions (temps, magasin, article...).  
✅ **Développement d’un processus ETL avec Semarchy xDI** – Ingestion, contrôle qualité et transformation de données brutes (fichiers plats, référentiels).  
✅ **Alimentation automatisée** du datawarehouse structuré pour l'analyse.  
✅ **Création de tableaux de bord Power BI** dynamiques connectés au DWH : suivi du chiffre d’affaires, volume, panier moyen par axes d’analyse variés.

#### 🎯 Résultats  
🔹 **Datawarehouse centralisé** assurant une source unique de vérité sur les ventes internationales.  
🔹 **ETL robuste** garantissant la qualité, l’automatisation et la traçabilité des flux de données.  
🔹 **Dashboarding efficace** pour un pilotage commercial multi-dimensions.

 📂 **Lien vers le projet** : [Accéder au projet](https://github.com/Derka88/cabinet-datawarehouse)

<br>

### Nom du projet

#### 🚀 Problème à résoudre
 
#### 📌 Réalisations  
✅
✅
✅

#### 🛠️ Technologies  

#### 🎯 Résultats  
🔹
🔹
🔹

<br>

### Nom du projet

#### 🚀 Problème à résoudre
 
#### 📌 Réalisations  
✅
✅
✅

#### 🛠️ Technologies  

#### 🎯 Résultats  
🔹
🔹
🔹
 

<br>
---

## 🌍 Langues  
- 🇫🇷 **Français** – Langue maternelle  
- 🇬🇧 **Anglais** – Niveau B2

---

## 🎯 Centres d'intérêt  *(Parce que j’ai une vie en dehors des datasets)*
- 🏀 **Basket** – 8 ans de pratique, toujours prêt pour un pick-up game.
- ⚽ **Football** – Passionné d’analyses tactiques et de stats de joueurs.
- 🎬 **Films Marvel** – Team **Tony Stark** all the way ! 
- 📊 **Sport & Data** – J’adore analyser les perfs des joueurs et des équipes.

> Merci d’avoir pris le temps de lire mon portfolio ! 🙌 **Si tu veux parler data, sport ou Marvel, n’hésite pas à me contacter !** 🚀
